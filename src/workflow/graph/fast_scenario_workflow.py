"""
åŸºäº ReAct æ¶æ„çš„å¿«é€Ÿæƒ…æ™¯ç®¡ç†å·¥ä½œæµ
å®Œå…¨è„±ç¦» LangGraph æ¡†æ¶ï¼Œä½¿ç”¨ä¸¤ä¸ª ReActAgent å®ç°è®°å¿†é—ªå›å’Œæƒ…æ™¯æ›´æ–°
"""

import asyncio
import sys
import os
from typing import Dict, Any, List, AsyncGenerator
from openai import AsyncOpenAI

# Add project root to Python path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from config.manager import settings
from src.workflow.graph.reAct import ReActAgent
from src.prompts.fast_memory_search_prompts import SEARCH_LLM_PROMPT, SEARCH_USER_TEMPLATE
from src.prompts.fast_scenario_edit_prompts import EDIT_LLM_PROMPT, EDIT_USER_TEMPLATE
from src.workflow.tools.re_search_tool import create_re_search_tool, messages_to_txt
from src.workflow.tools.simple_thinking import thinking_tool
from src.workflow.tools.scenario_table_tools import (
    scenario_manager, 
    table_tools
)
from src.workflow.tools.wikipedia_search_tool import create_wikipedia_search_tool
from utils.external_knowledge_manager import external_knowledge_manager


class FastReActWorkflow:
    """åŸºäº ReAct æ¶æ„çš„å¿«é€Ÿæƒ…æ™¯ç®¡ç†å·¥ä½œæµ"""
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥ä½œæµ"""
        # scenario_manager ç°åœ¨ä¼šè‡ªåŠ¨åˆå§‹åŒ–ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒç”¨
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        agent_config = settings.agent
        self.client = AsyncOpenAI(
            api_key=agent_config.api_key,
            base_url=agent_config.base_url
        )
        
    
    def _build_search_tools(self, messages: List[Dict[str, Any]]):
        """æ„å»ºæœç´¢å·¥å…·åˆ—è¡¨"""
        tools = []
        
        # æ·»åŠ æ€è€ƒå·¥å…·
        tools.append(thinking_tool)
        
        # åˆ›å»ºæœç´¢æ–‡æœ¬
        search_text = messages_to_txt(messages)
        
        # ä»ç®¡ç†å™¨è·å–å·²ç¼“å­˜çš„å¤–éƒ¨çŸ¥è¯†åº“å†…å®¹
        external_knowledge = external_knowledge_manager.get_knowledge_content()
        if external_knowledge:
            # å°†å¤–éƒ¨çŸ¥è¯†åº“å†…å®¹æ·»åŠ åˆ°æœç´¢æ–‡æœ¬å‰é¢
            search_text = f"=== å¤–éƒ¨çŸ¥è¯†åº“ ===\n{external_knowledge}\n\n=== å¯¹è¯å†å² ===\n{search_text}"
            print(f"\\ ä½¿ç”¨å·²ç¼“å­˜çš„å¤–éƒ¨çŸ¥è¯†åº“: {external_knowledge_manager.get_knowledge_path()}", flush=True)
        
        # æ·»åŠ è®°å¿†æœç´¢å·¥å…·
        memory_search_tool = create_re_search_tool(search_text)
        tools.append(memory_search_tool)
        
        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦æ·»åŠ Wikipediaå·¥å…·
        if settings.agent.enable_wiki_search:
            tools.append(create_wikipedia_search_tool())
        
        return tools
    
    def _build_edit_tools(self):
        """æ„å»ºç¼–è¾‘å·¥å…·åˆ—è¡¨"""
        # ä» table_tools ä¸­ç­›é€‰éœ€è¦çš„å·¥å…·
        edit_tool_names = ['create_row', 'update_cell', 'delete_row']
        return [
            tool for tool in table_tools 
            if tool['function'].__name__ in edit_tool_names
        ]
    
    def _extract_latest_ai_message(self, messages: List[Dict[str, Any]], offset: int = 1) -> str:
        """æå–æœ€æ–°çš„AIæ¶ˆæ¯"""
        ai_messages = []
        for msg in messages:
            if msg.get("role") == "assistant":
                ai_messages.append(msg.get("content", ""))
        
        if len(ai_messages) >= offset:
            return ai_messages[-offset]
        elif ai_messages:
            return ai_messages[-1]
        else:
            return ""
    

    async def run(self, state: Dict[str, Any]) -> AsyncGenerator[str, None]:
        """è¿è¡Œå¿«é€Ÿ ReAct å·¥ä½œæµ
        
        Args:
            state: å·¥ä½œæµçŠ¶æ€ï¼ŒåŒ…å«messagesã€session_timestampç­‰ä¿¡æ¯
            
        Yields:
            str: æµå¼è¾“å‡ºçš„å¤„ç†ç»“æœ
        """
        try:
            print("ğŸ¤– Fast ReAct Scenario Workflow starting...", flush=True)
            
            # è·å–è¾“å…¥æ•°æ®
            messages = state.get("messages", [])
            current_scenario = state.get("current_scenario", "")
            session_timestamp = state.get("session_timestamp")
            
            # å¦‚æœæ²¡æœ‰æä¾›session_timestampï¼Œç”Ÿæˆä¸€ä¸ª
            if not session_timestamp:
                from datetime import datetime
                session_timestamp = datetime.now().strftime("%Y_%m_%d_%H_%M_%S")
            
            # å¦‚æœæ²¡æœ‰current_scenarioï¼Œä»scenario_managerè¯»å–
            if not current_scenario:
                current_scenario = scenario_manager.get_all_pretty_tables(
                    description=True, 
                    operation_guide=True
                )
                print(f"\\ åŠ è½½æƒ…æ™¯è¡¨æ ¼ï¼Œæ€»é•¿åº¦: {len(current_scenario)}", flush=True)
            
            # å¦‚æœé…ç½®ä¸º-1ï¼Œè‡ªåŠ¨æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå†…å®¹é•¿åº¦>100çš„AIæ¶ˆæ¯ç´¢å¼•
            ai_msg_index = settings.langgraph.last_ai_messages_index
            if ai_msg_index == -1:
                from utils.messages_process import auto_find_ai_message_index
                ai_msg_index = auto_find_ai_message_index(messages)
            
            # æå–æœ€æ–°AIæ¶ˆæ¯
            last_ai_message = self._extract_latest_ai_message(messages, ai_msg_index)
            
            # è·å–é…ç½®
            agent_config = settings.agent
            log_config = settings.log
            
            # åˆ›å»ºä¼šè¯æ—¥å¿—ç›®å½•
            session_log_path = log_config.get_session_log_path(session_timestamp)
            
            print(f"\\ æ¥æ”¶æ¶ˆæ¯æ•°: {len(messages)}, AIæ¶ˆæ¯é•¿åº¦: {len(last_ai_message)}", flush=True)
            print(f"\\ ä¼šè¯æ—¥å¿—ç›®å½•: {session_log_path}", flush=True)
            
            # === é˜¶æ®µ1ï¼šæœç´¢è®°å¿† ReAct Agent ===
            print("âœ… Phase 1: Memory Search Agent...", flush=True)
            
            # æ„å»ºæœç´¢å·¥å…·åˆ—è¡¨
            search_tools = self._build_search_tools(messages)
            
            # æ„å»ºæœç´¢ç”¨æˆ·è¾“å…¥
            search_user_input = SEARCH_USER_TEMPLATE.format(
                current_scenario=current_scenario,
                last_ai_message=last_ai_message
            )
            
            # åˆ›å»ºæœç´¢ ReAct æ™ºèƒ½ä½“ï¼ˆé™åˆ¶1æ¬¡è¿­ä»£ï¼‰
            search_agent = ReActAgent(
                model=self.client,
                max_iterations=1,  # å¼ºåˆ¶é™åˆ¶ä¸º1æ¬¡è¿­ä»£
                system_prompt=SEARCH_LLM_PROMPT,
                user_input=search_user_input,
                tools_with_schemas=search_tools,
                model_name=agent_config.model,
                temperature=agent_config.temperature,
                max_tokens=agent_config.max_tokens if hasattr(agent_config, 'max_tokens') else None,
                history_type=log_config.history_format if log_config.enable_agent_history else "none",
                history_path=session_log_path
            )
            
            # æ ¹æ®é…ç½®é€‰æ‹©æµå¼æ–¹æ³•æ‰§è¡Œæœç´¢æ™ºèƒ½ä½“ï¼Œæ”¶é›†LLMè¾“å‡ºï¼ˆç”¨äºå±•ç¤ºï¼‰
            search_model_output = ""
            if agent_config.stream_mode:
                # çœŸæµå¼ï¼šå®æ—¶å­—ç¬¦è¾“å‡º
                async for chunk in search_agent.astream():
                    search_model_output += chunk
                    yield chunk
            else:
                # ä¼ªæµå¼ï¼šæ¯æ¬¡è¿­ä»£è¾“å‡ºå®Œæ•´å“åº”
                async for chunk in search_agent.ainvoke():
                    search_model_output += chunk
                    yield chunk

            # ä¿®æ­£ï¼šä½¿ç”¨å·¥å…·æ‰§è¡Œçš„çœŸå®è¾“å‡ºä½œä¸ºæœç´¢ç»“æœï¼ˆè€Œéæ¨¡å‹æ–‡æœ¬ï¼‰
            search_tool_output = search_agent.get_tool_outputs_text()
            
            
            # === é˜¶æ®µ2ï¼šç¼–è¾‘æƒ…æ™¯ ReAct Agent ===
            print("âœ… Phase 2: Scenario Edit Agent...", flush=True)
            
            # æ„å»ºç¼–è¾‘å·¥å…·åˆ—è¡¨
            edit_tools = self._build_edit_tools()
            
            # æ„å»ºç¼–è¾‘ç”¨æˆ·è¾“å…¥ï¼ˆåŒ…å«ç¬¬ä¸€é˜¶æ®µçš„å·¥å…·æœç´¢ç»“æœï¼‰
            edit_user_input = EDIT_USER_TEMPLATE.format(
                current_scenario=current_scenario,
                last_ai_message=last_ai_message,
                # ä¼ å…¥ç¬¬ä¸€é˜¶æ®µå·¥å…·çš„è¾“å‡ºç»“æœï¼ˆä¿®æ­£å‰ä¸ºæ¨¡å‹è¾“å‡ºï¼Œç°å·²ä¿®æ­£ï¼‰
                search_results=search_tool_output
            )
            
            # åŠ¨æ€å¡«å……ç¼–è¾‘ç³»ç»Ÿæç¤ºè¯ä¸­çš„schema
            dynamic_edit_system_prompt = EDIT_LLM_PROMPT.format(
                schema_text=scenario_manager.get_table_schema_text()
            )
            
            # åˆ›å»ºç¼–è¾‘ ReAct æ™ºèƒ½ä½“ï¼ˆé™åˆ¶1æ¬¡è¿­ä»£ï¼‰
            edit_agent = ReActAgent(
                model=self.client,
                max_iterations=1,  # å¼ºåˆ¶é™åˆ¶ä¸º1æ¬¡è¿­ä»£
                system_prompt=dynamic_edit_system_prompt,
                user_input=edit_user_input,
                tools_with_schemas=edit_tools,
                model_name=agent_config.model,
                temperature=agent_config.temperature,
                max_tokens=agent_config.max_tokens if hasattr(agent_config, 'max_tokens') else None,
                history_type=log_config.history_format if log_config.enable_agent_history else "none",
                history_path=session_log_path
            )
            
            # æ ¹æ®é…ç½®é€‰æ‹©æµå¼æ–¹æ³•æ‰§è¡Œç¼–è¾‘æ™ºèƒ½ä½“
            if agent_config.stream_mode:
                # çœŸæµå¼ï¼šå®æ—¶å­—ç¬¦è¾“å‡º
                async for chunk in edit_agent.astream():
                    yield chunk
            else:
                # ä¼ªæµå¼ï¼šæ¯æ¬¡è¿­ä»£è¾“å‡ºå®Œæ•´å“åº”
                async for chunk in edit_agent.ainvoke():
                    yield chunk
                
            print("\nâœ… Fast ReAct Scenario Workflow completed!", flush=True)
            
        except Exception as e:
            error_msg = f"âŒ Fast ReAct Workflow æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(error_msg, flush=True)
            yield error_msg


# åˆ›å»ºå·¥ä½œæµå®ä¾‹çš„å·¥å‚å‡½æ•°
def create_fast_scenario_workflow() -> FastReActWorkflow:
    """åˆ›å»ºå¿«é€Ÿ ReAct æƒ…æ™¯ç®¡ç†å·¥ä½œæµå®ä¾‹"""
    return FastReActWorkflow()


# æµ‹è¯•å‡½æ•°
async def test_fast_react_workflow():
    """æµ‹è¯•å¿«é€Ÿ ReAct å·¥ä½œæµ"""
    try:
        print("=== æµ‹è¯• Fast ReAct æƒ…æ™¯ç®¡ç†å·¥ä½œæµ ===")
        
        # åˆ›å»ºå·¥ä½œæµ
        workflow = create_fast_scenario_workflow()
        
        # æ¨¡æ‹Ÿè¾“å…¥çŠ¶æ€
        test_state = {
            "messages": [
                {"role": "user", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯æ–°æ¥çš„é­”æ³•å­¦é™¢å­¦ç”Ÿ"},
                {"role": "assistant", "content": "æ¬¢è¿æ¥åˆ°éœæ ¼æ²ƒèŒ¨ï¼æˆ‘æ˜¯ä½ çš„å¯¼å¸ˆæ•™æˆã€‚è®©æˆ‘ä¸ºä½ ä»‹ç»ä¸€ä¸‹è¿™é‡Œçš„ç¯å¢ƒå’Œè§„åˆ™ã€‚"}
            ]
        }
        
        print("ğŸƒ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
        
        # æµå¼æ‰§è¡Œ
        async for chunk in workflow.run(test_state):
            print(chunk, end='', flush=True)
            
        print("\n\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_fast_react_workflow())