import asyncio
import json
import uuid
import os
from typing import List, Dict, Any, AsyncGenerator, Optional
from openai import AsyncOpenAI


class ReActAgent:
    def __init__(self, model: AsyncOpenAI, max_iterations: int, system_prompt: str, user_input: str, tools_with_schemas: List[Dict[str, Any]], 
                 model_name: str = "gpt-3.5-turbo", temperature: float = 0.1, max_tokens: Optional[int] = None, 
                 top_p: Optional[float] = None, frequency_penalty: Optional[float] = None, presence_penalty: Optional[float] = None,
                 history_type: str = "txt", history_path: str = "."):
        self.model = model
        self.max_iterations = max_iterations
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.top_p = top_p
        self.frequency_penalty = frequency_penalty
        self.presence_penalty = presence_penalty
        self.history_type = history_type
        self.history_path = history_path
        
        # ä» tools_with_schemas æå–å·¥å…·å‡½æ•°å’Œschema
        self.tools = {tool["schema"]["function"]["name"]: tool["function"] for tool in tools_with_schemas}
        self.tools_schemas = [tool["schema"] for tool in tools_with_schemas]
        
        # ç”Ÿæˆå·¥å…·æè¿°å¹¶åµŒå…¥åˆ°ç³»ç»Ÿæç¤ºè¯
        tool_descriptions = self._generate_tool_descriptions(self.tools_schemas)
        self.system_prompt = system_prompt + tool_descriptions
        self.user_input = user_input
    
    def _generate_tool_descriptions(self, tools_schemas: List[Dict[str, Any]]) -> str:
        """
        ä» OpenAI schema ç”Ÿæˆç»Ÿä¸€çš„å·¥å…·æè¿°
        
        Args:
            tools_schemas: OpenAI å·¥å…· schema åˆ—è¡¨
            
        Returns:
            str: å·¥å…·æè¿°å­—ç¬¦ä¸²
        """
        header = """

<å·¥å…·è¯´æ˜>
å¦‚æœä½ è¦è°ƒç”¨å·¥å…·ï¼Œåˆ™å¿…é¡»åœ¨æ­£æ–‡ä¸­ä»¥JSONæ ¼å¼è¾“å‡ºå·¥å…·è°ƒç”¨ï¼Œä¸å¯ä»¥è¾“å‡ºJSONå¤–çš„ä»»ä½•å†…å®¹ã€‚æ”¯æŒå¹¶å‘è°ƒç”¨å¤šä¸ªå·¥å…·ã€‚
æ ¼å¼è¦æ±‚ç¤ºä¾‹ï¼š
```json
{
  "tool_calls": [
    {
      "tool_name": "å·¥å…·åç§°1",
      "arguments": {"å‚æ•°å": "å‚æ•°å€¼"}
    },
    {
      "tool_name": "å·¥å…·åç§°2",
      "arguments": {"å‚æ•°å": "å‚æ•°å€¼"}
    }
  ]
}
```

å¯ç”¨å·¥å…·ï¼š
"""
        
        tool_descriptions = [header]
        
        for i, schema in enumerate(tools_schemas):
            function_schema = schema.get("function", {})
            tool_name = function_schema.get("name", "unknown")
            tool_description = function_schema.get("description", "æ— æè¿°")
            parameters = function_schema.get("parameters", {})
            
            # å·¥å…·åˆ†éš”çº¿
            if i > 0:
                tool_descriptions.append("---")
            
            # å·¥å…·åç§°å’Œæè¿°
            tool_descriptions.append(f"å·¥å…·: {tool_name}")
            tool_descriptions.append(f"æè¿°: {tool_description.strip()}")
            
            # è§£æå‚æ•°
            properties = parameters.get("properties", {})
            required = parameters.get("required", [])
            
            if properties:
                tool_descriptions.append("å‚æ•°:")
                for param_name, param_info in properties.items():
                    param_type = param_info.get("type", "string")
                    param_desc = param_info.get("description", "")
                    is_required = param_name in required
                    required_text = "å¿…éœ€" if is_required else "å¯é€‰"
                    
                    if param_desc:
                        tool_descriptions.append(f"  - {param_name} ({param_type}, {required_text}): {param_desc}")
                    else:
                        tool_descriptions.append(f"  - {param_name} ({param_type}, {required_text})")
            else:
                tool_descriptions.append("å‚æ•°: æ— ")
            
            tool_descriptions.append("")  # ç©ºè¡Œ
        
        tool_descriptions.append("</å·¥å…·è¯´æ˜>")
        return "\n".join(tool_descriptions)
    
    async def ainvoke(self) -> AsyncGenerator[str, None]:
        """å¼‚æ­¥è§¦å‘ ReAct Agentï¼Œä¼ªæµå¼è¿”å›ç»“æœï¼ˆæ¯æ¬¡è¿­ä»£è¾“å‡ºå®Œæ•´å“åº”ï¼‰"""
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": self.user_input}
        ]
        current_messages = messages.copy()
        iteration = 0
        
        while iteration < self.max_iterations:
            iteration += 1
            
            # LLM éæµå¼ç”Ÿæˆå“åº”
            response = await self._get_llm_response(current_messages)
            
            # å°†è¿™æ¬¡è¿­ä»£çš„å®Œæ•´å“åº”ä½œä¸ºä¸€ä¸ªchunkè¾“å‡º
            yield response
            
            # æ·»åŠ  assistant æ¶ˆæ¯åˆ°å¯¹è¯å†å²
            current_messages.append({"role": "assistant", "content": response})
            
            # è§£æå·¥å…·è°ƒç”¨
            tool_calls = self._parse_tool_calls(response)
            
            if not tool_calls:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¾ªç¯
                break
            
            # ä¸ºå·¥å…·è°ƒç”¨æ·»åŠ  tool_call_id å¹¶æ›´æ–°æ¶ˆæ¯
            tool_calls_with_id = []
            for tool_call in tool_calls:
                tool_call_id = f"call_{uuid.uuid4().hex[:8]}"
                tool_call_with_id = {
                    "id": tool_call_id,
                    "type": "function",
                    "function": {
                        "name": tool_call["tool_name"],
                        "arguments": json.dumps(tool_call["arguments"])
                    }
                }
                tool_calls_with_id.append(tool_call_with_id)
            
            # æ›´æ–°æœ€åä¸€æ¡ assistant æ¶ˆæ¯ï¼Œæ·»åŠ  tool_calls
            current_messages[-1]["tool_calls"] = tool_calls_with_id
            
            # å¹¶å‘æ‰§è¡Œå·¥å…·
            tool_results = await self._execute_tools_concurrently(tool_calls_with_id)
            
            # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
            for result in tool_results:
                tool_message = {
                    "role": "tool",
                    "tool_call_id": result["tool_call_id"],
                    "content": result["content"]
                }
                # æ·»åŠ  tool_name å­—æ®µç”¨äºè°ƒè¯•å’Œè¿½è¸ª
                if "tool_name" in result:
                    tool_message["name"] = result["tool_name"]
                current_messages.append(tool_message)
        
        # ä¿å­˜æœ€ç»ˆçš„ messages åˆ° JSON æ–‡ä»¶
        await self._save_messages(current_messages)
    
    async def astream(self) -> AsyncGenerator[str, None]:
        """å¼‚æ­¥è§¦å‘ ReAct Agentï¼Œæµå¼è¿”å›ç»“æœ"""
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": self.user_input}
        ]
        current_messages = messages.copy()
        iteration = 0
        
        while iteration < self.max_iterations:
            iteration += 1
            
            # LLM æµå¼ç”Ÿæˆå“åº”
            full_response = ""
            async for chunk in self._stream_llm_response(current_messages):
                full_response += chunk
                yield chunk
            
            # æ·»åŠ  assistant æ¶ˆæ¯åˆ°å¯¹è¯å†å²
            current_messages.append({"role": "assistant", "content": full_response})
            
            # è§£æå·¥å…·è°ƒç”¨
            tool_calls = self._parse_tool_calls(full_response)
            
            if not tool_calls:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¾ªç¯
                break
            
            # ä¸ºå·¥å…·è°ƒç”¨æ·»åŠ  tool_call_id å¹¶æ›´æ–°æ¶ˆæ¯
            tool_calls_with_id = []
            for tool_call in tool_calls:
                tool_call_id = f"call_{uuid.uuid4().hex[:8]}"
                tool_call_with_id = {
                    "id": tool_call_id,
                    "type": "function",
                    "function": {
                        "name": tool_call["tool_name"],
                        "arguments": json.dumps(tool_call["arguments"])
                    }
                }
                tool_calls_with_id.append(tool_call_with_id)
            
            # æ›´æ–°æœ€åä¸€æ¡ assistant æ¶ˆæ¯ï¼Œæ·»åŠ  tool_calls
            current_messages[-1]["tool_calls"] = tool_calls_with_id
            
            # å¹¶å‘æ‰§è¡Œå·¥å…·
            tool_results = await self._execute_tools_concurrently(tool_calls_with_id)
            
            # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
            for result in tool_results:
                tool_message = {
                    "role": "tool",
                    "tool_call_id": result["tool_call_id"],
                    "content": result["content"]
                }
                # æ·»åŠ  tool_name å­—æ®µç”¨äºè°ƒè¯•å’Œè¿½è¸ª
                if "tool_name" in result:
                    tool_message["name"] = result["tool_name"]
                current_messages.append(tool_message)
        
        # ä¿å­˜æœ€ç»ˆçš„ messages åˆ° JSON æ–‡ä»¶
        await self._save_messages(current_messages)
    
    async def _stream_llm_response(self, messages: List[Dict[str, str]]) -> AsyncGenerator[str, None]:
        """æµå¼è·å– LLM å“åº”"""
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                "model": self.model_name,
                "messages": messages,
                "stream": True,
                "temperature": self.temperature
            }
            
            # æ·»åŠ å¯é€‰å‚æ•°
            if self.max_tokens is not None:
                params["max_tokens"] = self.max_tokens
            if self.top_p is not None:
                params["top_p"] = self.top_p
            if self.frequency_penalty is not None:
                params["frequency_penalty"] = self.frequency_penalty
            if self.presence_penalty is not None:
                params["presence_penalty"] = self.presence_penalty
            
            stream = await self.model.chat.completions.create(**params)
            
            async for chunk in stream:
                if chunk.choices and len(chunk.choices) > 0 and chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
        except Exception as e:
            yield f"é”™è¯¯: {str(e)}"
    
    async def _get_llm_response(self, messages: List[Dict[str, str]]) -> str:
        """éæµå¼è·å– LLM å“åº”"""
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                "model": self.model_name,
                "messages": messages,
                "stream": False,
                "temperature": self.temperature
            }
            
            # æ·»åŠ å¯é€‰å‚æ•°
            if self.max_tokens is not None:
                params["max_tokens"] = self.max_tokens
            if self.top_p is not None:
                params["top_p"] = self.top_p
            if self.frequency_penalty is not None:
                params["frequency_penalty"] = self.frequency_penalty
            if self.presence_penalty is not None:
                params["presence_penalty"] = self.presence_penalty
            
            response = await self.model.chat.completions.create(**params)
            if response.choices and len(response.choices) > 0:
                return response.choices[0].message.content or ""
            else:
                return ""
        except Exception as e:
            return f"é”™è¯¯: {str(e)}"
    
    def _parse_tool_calls(self, response: str) -> List[Dict[str, Any]]:
        """è§£æ LLM å“åº”ä¸­çš„å·¥å…·è°ƒç”¨"""
        try:
            import re
            
            # é¦–å…ˆå°è¯•æŸ¥æ‰¾ JSON ä»£ç å—
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # å°è¯•æŸ¥æ‰¾ç›´æ¥çš„ JSON å¯¹è±¡ï¼ˆä¸åœ¨ä»£ç å—ä¸­ï¼‰
                json_match = re.search(r'(\{[^{}]*"tool_calls"[^{}]*\})', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    # æœ€åå°è¯•æ•´ä¸ªå“åº”æ˜¯å¦å°±æ˜¯JSON
                    json_str = response.strip()
            
            parsed = json.loads(json_str)
            
            if "tool_calls" in parsed and isinstance(parsed["tool_calls"], list):
                return parsed["tool_calls"]
            
            return []
        except (json.JSONDecodeError, KeyError):
            return []
    
    async def _execute_tools_concurrently(self, tool_calls_with_id: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """å¹¶å‘æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        async def execute_single_tool(tool_call):
            tool_call_id = tool_call["id"]
            tool_name = tool_call["function"]["name"]
            arguments = json.loads(tool_call["function"]["arguments"])
            
            try:
                if tool_name in self.tools:
                    if asyncio.iscoroutinefunction(self.tools[tool_name]):
                        result = await self.tools[tool_name](**arguments)
                    else:
                        result = self.tools[tool_name](**arguments)
                    return {
                        "tool_call_id": tool_call_id,
                        "tool_name": tool_name,
                        "content": str(result)
                    }
                else:
                    return {
                        "tool_call_id": tool_call_id,
                        "tool_name": tool_name,
                        "content": f"é”™è¯¯: æœªçŸ¥å·¥å…· '{tool_name}'"
                    }
            except Exception as e:
                return {
                    "tool_call_id": tool_call_id,
                    "tool_name": tool_name,
                    "content": f"é”™è¯¯: {str(e)}"
                }
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
        tasks = [execute_single_tool(tool_call) for tool_call in tool_calls_with_id]
        return await asyncio.gather(*tasks)
    
    async def _save_messages(self, messages: List[Dict[str, Any]]):
        """æ ¹æ®é…ç½®ä¿å­˜æ¶ˆæ¯å†å²"""
        if self.history_type == "none":
            return
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.history_path, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        file_id = uuid.uuid4().hex[:8]
        
        if self.history_type == "json":
            filename = f"messages_{file_id}.json"
            filepath = os.path.join(self.history_path, filename)
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(messages, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“ å¯¹è¯è®°å½•å·²ä¿å­˜åˆ°: {filepath}")
        elif self.history_type == "txt":
            filename = f"messages_{file_id}.txt"
            filepath = os.path.join(self.history_path, filename)
            await self._save_messages_as_txt(messages, filepath)
            print(f"ğŸ“ å¯¹è¯è®°å½•å·²ä¿å­˜åˆ°: {filepath}")
        else:
            print(f"è­¦å‘Š: æœªçŸ¥çš„ history_type '{self.history_type}'ï¼Œè·³è¿‡ä¿å­˜")
    
    def _format_json_content(self, content: str) -> str:
        """æ ¼å¼åŒ– JSON å†…å®¹ä¸ºå±‚çº§é€’è¿›çš„æ–‡æœ¬"""
        try:
            parsed = json.loads(content)
            return json.dumps(parsed, ensure_ascii=False, indent=2)
        except (json.JSONDecodeError, TypeError):
            return content
    
    async def _save_messages_as_txt(self, messages: List[Dict[str, Any]], filepath: str):
        """ä¿å­˜æ¶ˆæ¯å†å²ä¸ºç¾åŒ–çš„æ–‡æœ¬æ ¼å¼"""
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("=" * 34 + "    Start    " + "=" * 34 + "\n")
            
            for message in messages:
                role = message.get("role", "unknown")
                
                if role == "system":
                    f.write("=" * 33 + " System Message " + "=" * 33 + "\n")
                    f.write("content: \n")
                    f.write(message.get("content", "") + "\n\n")
                
                elif role == "user":
                    f.write("=" * 34 + " User Message " + "=" * 34 + "\n")
                    f.write("content: \n")
                    f.write(message.get("content", "") + "\n\n")
                
                elif role == "assistant":
                    f.write("=" * 34 + " AI Message " + "=" * 35 + "\n")
                    f.write("content: \n")
                    content = message.get("content", "")
                    formatted_content = self._format_json_content(content)
                    f.write(formatted_content + "\n\n")
                
                elif role == "tool":
                    f.write("=" * 33 + " Tool Message " + "=" * 33 + "\n")
                    f.write("\n\n")
                    
                    # tool_call_id
                    if "tool_call_id" in message:
                        f.write("tool_call_id\n")
                        f.write("    " + message["tool_call_id"] + "\n")
                    
                    # name (tool name)
                    if "name" in message:
                        f.write("name: \n")
                        f.write("    " + message["name"] + "\n")
                    
                    # content
                    f.write("content: \n")
                    f.write("    " + message.get("content", "") + "\n\n")
            
            f.write("=" * 34 + "    END    " + "=" * 35 + "\n")