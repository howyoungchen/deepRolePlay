"""
ä»£ç†æœåŠ¡çš„ç»Ÿä¸€å·¥å…·ç±»é›†åˆ
åŒ…å«è®¤è¯ã€å“åº”æ„å»ºã€æµå¼å¤„ç†ã€å·¥ä½œæµè¾…åŠ©ã€æ—¥å¿—è®°å½•å’Œç›®å½•æ“ä½œç­‰åŠŸèƒ½
"""
import json
import time
import uuid
import base64
import os
import glob
from typing import Dict, Any, Optional, List, Callable, AsyncGenerator
from fastapi import Request, Response
from fastapi.responses import StreamingResponse, JSONResponse
from config.manager import settings


class AuthUtils:
    """APIå¯†é’¥å’Œè®¤è¯å·¥å…·ç±»"""
    
    @staticmethod
    def extract_api_key(request: Request) -> str:
        """ä»è¯·æ±‚ä¸­æå–APIå¯†é’¥ï¼Œä¼˜å…ˆä½¿ç”¨è¯·æ±‚å¤´ï¼Œå¦åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶"""
        auth_header = request.headers.get("Authorization", "")
        api_key = ""
        
        if auth_header.startswith("Bearer "):
            api_key = auth_header[7:]
        
        if not api_key:
            api_key = settings.proxy.api_key
        
        return api_key
    
    @staticmethod
    def get_request_headers(request: Request) -> dict:
        """è·å–è½¬å‘è¯·æ±‚æ‰€éœ€çš„å¤´éƒ¨ä¿¡æ¯"""
        headers = {
            "Content-Type": "application/json",
            "User-Agent": "DeepRolePlay-Proxy/1.0"
        }
        
        auth_header = request.headers.get("authorization")
        if auth_header:
            headers["Authorization"] = auth_header
        
        return headers


class ResponseBuilder:
    """ç»Ÿä¸€çš„OpenAIå…¼å®¹å“åº”æ„å»ºå™¨"""
    
    @staticmethod
    def create_chat_completion_response(
        request_id: str,
        model: str,
        content: str,
        stream: bool = False,
        finish_reason: str = "stop",
        usage_tokens: Optional[Dict[str, int]] = None
    ) -> Dict[str, Any]:
        """åˆ›å»ºèŠå¤©å®Œæˆå“åº”"""
        base_response = {
            "id": f"chatcmpl-{request_id}",
            "created": int(time.time()),
            "model": model,
        }
        
        if stream:
            base_response.update({
                "object": "chat.completion.chunk",
                "choices": [{
                    "index": 0,
                    "delta": {
                        "role": "assistant",
                        "content": content
                    },
                    "finish_reason": finish_reason
                }]
            })
        else:
            base_response.update({
                "object": "chat.completion",
                "choices": [{
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": content
                    },
                    "finish_reason": finish_reason
                }],
                "usage": usage_tokens or {
                    "prompt_tokens": 10,
                    "completion_tokens": len(content),
                    "total_tokens": 10 + len(content)
                }
            })
        
        return base_response
    
    @staticmethod
    def create_special_response(response_type: str, request_id: str, model: str, stream: bool = False) -> Dict[str, Any]:
        """åˆ›å»ºç‰¹æ®Šå“åº”ï¼ˆè°ƒè¯•æ¨¡å¼ã€æ–°å¯¹è¯ç­‰ï¼‰"""
        if response_type == "debug":
            try:
                with open("/home/chiye/worklab/deepRolePlay/pics/generate.png", "rb") as img_file:
                    img_data = base64.b64encode(img_file.read()).decode('utf-8')
                    content = (f'Testing two images display:\n\nå›¾ç‰‡1:\n'
                              f'<img src="data:image/png;base64,{img_data}" alt="Wizard 1" style="max-width: 300px;">'
                              f'<img src="data:image/png;base64,{img_data}" alt="Wizard 2" style="max-width: 300px;">')
            except FileNotFoundError:
                content = "ğŸ§™â€â™‚ï¸ Wizard image not found, but the magic continues!"
        elif response_type == "new_conversation":
            content = "A new conversation has been successfully started."
        else:
            content = f"Special response: {response_type}"
        
        return ResponseBuilder.create_chat_completion_response(
            request_id=request_id,
            model=model,
            content=content,
            stream=stream
        )
    
    @staticmethod
    def create_error_response(
        error_message: str,
        error_type: str = "server_error",
        error_code: str = "INTERNAL_ERROR",
        status_code: int = 500
    ) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯å“åº”"""
        return {
            "error": {
                "message": error_message,
                "type": error_type,
                "code": error_code
            }
        }


class StreamingHandler:
    """ç»Ÿä¸€çš„æµå¼å“åº”å¤„ç†å™¨"""
    
    @staticmethod
    async def create_simple_streaming_response(
        request: Request,
        response_data: Dict[str, Any],
        request_id: Optional[str] = None,
        extra_headers: Optional[Dict[str, str]] = None,
        log_data: Optional[Dict[str, Any]] = None
    ) -> StreamingResponse:
        """åˆ›å»ºç®€å•çš„æµå¼å“åº”ï¼ˆç”¨äºè°ƒè¯•æ¨¡å¼å’Œæ–°å¯¹è¯ï¼‰"""
        if not request_id:
            request_id = str(uuid.uuid4())
        
        async def stream_generator():
            yield f"data: {json.dumps(response_data)}\n\n"
            yield "data: [DONE]\n\n"
        
        headers = {
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Request-ID": request_id
        }
        
        if extra_headers:
            headers.update(extra_headers)
        
        response = StreamingResponse(
            stream_generator(),
            media_type="text/event-stream",
            headers=headers
        )
        
        # è®°å½•æ—¥å¿—
        if log_data:
            LoggingUtils.log_response(
                request=request,
                response=response,
                request_body=log_data.get("request_body", {}),
                response_body=log_data.get("response_body", {}),
                duration=log_data.get("duration", 0.001),
                request_id=request_id
            )
        
        return response
    
    @staticmethod
    def create_workflow_streaming_response(
        request: Request,
        workflow_generator: Callable,
        request_id: Optional[str] = None
    ) -> StreamingResponse:
        """åˆ›å»ºå·¥ä½œæµçš„æµå¼å“åº”"""
        if not request_id:
            request_id = str(uuid.uuid4())
        
        return StreamingResponse(
            workflow_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Request-ID": request_id
            }
        )


class WorkflowHelper:
    """å·¥ä½œæµç›¸å…³çš„è¾…åŠ©å·¥å…·ç±»"""
    
    @staticmethod
    def prepare_workflow_input(
        request,
        chat_request,
        request_id: str = None,
        current_scenario: str = ""
    ) -> Dict[str, Any]:
        """å‡†å¤‡å·¥ä½œæµè¾“å…¥æ•°æ®"""
        if not request_id:
            request_id = str(uuid.uuid4())
        
        api_key = AuthUtils.extract_api_key(request)
        
        return {
            "request_id": request_id,
            "original_messages": [msg.model_dump() for msg in chat_request.messages],
            "messages": [msg.model_dump() for msg in chat_request.messages],
            "current_scenario": current_scenario,
            "api_key": api_key,
            "model": chat_request.model,
            "stream": chat_request.stream
        }
    
    @staticmethod
    def check_new_conversation_trigger(messages: List) -> bool:
        """æ£€æŸ¥æ˜¯å¦è§¦å‘æ–°å¯¹è¯ï¼ˆæ£€æŸ¥æœ€åä¸¤æ¡ç”¨æˆ·æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«'deeproleplay'ï¼‰"""
        user_messages = [msg for msg in messages if msg.role == "user"]
        
        # è·å–æœ€åä¸¤æ¡ç”¨æˆ·æ¶ˆæ¯
        last_two_user_messages = user_messages[-2:] if len(user_messages) >= 2 else user_messages
        
        # æ£€æŸ¥'deeproleplay'å…³é”®å­—ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        for msg in last_two_user_messages:
            if "deeproleplay" in msg.content.lower():
                return True
        
        return False


class LoggingUtils:
    """æ—¥å¿—è®°å½•å·¥å…·ç±»"""
    
    @staticmethod
    def log_response(
        request: Request,
        response: Optional[Response],
        request_body: Dict[str, Any],
        response_body: Dict[str, Any],
        duration: float,
        request_id: str
    ):
        """è®°å½•è¯·æ±‚å“åº”æ—¥å¿—"""
        pass


class DirectoryUtils:
    """ç›®å½•æ“ä½œå·¥å…·ç±»"""
    
    @staticmethod
    def clear_scenarios_directory() -> bool:
        """æ¸…ç©ºscenariosç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
        try:
            scenarios_path = os.path.join(os.getcwd(), "scenarios")
            if os.path.exists(scenarios_path):
                files = glob.glob(os.path.join(scenarios_path, "*"))
                for file_path in files:
                    if os.path.isfile(file_path):
                        os.remove(file_path)
            return True
        except Exception as e:
            print(f"Failed to clear scenarios directory: {e}")
            return False


class SpecialRequestHandler:
    """ç»Ÿä¸€çš„ç‰¹æ®Šè¯·æ±‚å¤„ç†å™¨"""
    
    @staticmethod
    async def handle_special_request(
        request: Request,
        chat_request,
        request_type: str
    ):
        """ç»Ÿä¸€å¤„ç†ç‰¹æ®Šè¯·æ±‚ï¼ˆè°ƒè¯•æ¨¡å¼ã€æ–°å¯¹è¯ç­‰ï¼‰"""
        request_id = str(uuid.uuid4())
        
        # ç‰¹æ®Šæ“ä½œ
        if request_type == "new_conversation":
            DirectoryUtils.clear_scenarios_directory()
        
        # åˆ›å»ºå“åº”
        response_data = ResponseBuilder.create_special_response(
            request_type, request_id, chat_request.model, chat_request.stream
        )
        
        # å‡†å¤‡å¤´éƒ¨ä¿¡æ¯å’Œæ—¥å¿—æ•°æ®
        extra_headers = {f"X-{request_type.replace('_', '-').title()}": "true"}
        log_data = {
            "request_body": {
                "trigger" if request_type == "new_conversation" else f"{request_type}_mode": True,
                "model": chat_request.model
            },
            "response_body": {
                "message": "New conversation started" if request_type == "new_conversation" else f"{request_type} message",
                f"{request_type}": True,
                "stream": chat_request.stream
            }
        }
        
        if request_type == "new_conversation":
            log_data["response_body"]["scenarios_cleared"] = True
        
        if chat_request.stream:
            return await StreamingHandler.create_simple_streaming_response(
                request=request,
                response_data=response_data,
                request_id=request_id,
                extra_headers=extra_headers,
                log_data=log_data
            )
        else:
            response = JSONResponse(
                content=response_data,
                status_code=200,
                headers={**extra_headers, "X-Request-ID": request_id}
            )
            
            # è®°å½•æ—¥å¿—
            LoggingUtils.log_response(
                request=request,
                response=response,
                request_body=log_data["request_body"],
                response_body=log_data["response_body"],
                duration=0.001,
                request_id=request_id
            )
            
            return response