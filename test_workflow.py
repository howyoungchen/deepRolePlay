#!/usr/bin/env python3
"""
å·¥ä½œæµæµ‹è¯•è„šæœ¬ - æµ‹è¯•é‡æ„åçš„ scenario_workflow.py
æµ‹è¯•ä¸‰ä¸ªèŠ‚ç‚¹çš„ååŒå·¥ä½œï¼šmemory_flashback -> scenario_updater -> llm_forwarding

é…ç½®è¯´æ˜ï¼š
- ä»£ç†LLMï¼šä½¿ç”¨ config/config.yaml ä¸­çš„é…ç½®ï¼ˆç”¨äºè®°å¿†é—ªå›å’Œæƒ…æ™¯æ›´æ–°èŠ‚ç‚¹ï¼‰
- è½¬å‘LLMï¼šä½¿ç”¨æŒ‡å®šçš„ deepseek é…ç½®ï¼ˆç”¨äºæœ€ç»ˆç”¨æˆ·å›å¤ï¼‰
"""

import asyncio
import json
import time
import uuid
import sys
import os
from typing import Dict, Any, List, Optional
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.abspath(os.path.dirname(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥å·¥ä½œæµç›¸å…³æ¨¡å—
from src.workflow.graph.scenario_workflow import create_scenario_workflow
from utils.format_converter import convert_final_response, extract_content_from_event
from config.manager import settings

# æµ‹è¯•é…ç½®å¸¸é‡
DEEPSEEK_CONFIG = {
    "base_url": "https://api.deepseek.com/v1",
    "model": "deepseek-chat", 
    "api_key": "sk-5b155b212651493b942e7dca7dfb4751"
}

class Colors:
    """ç»ˆç«¯é¢œè‰²ä»£ç """
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    PURPLE = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    END = '\033[0m'

def print_header(title: str):
    """æ‰“å°æµ‹è¯•æ ‡é¢˜"""
    print(f"\n{Colors.CYAN}{Colors.BOLD}{'='*60}{Colors.END}")
    print(f"{Colors.CYAN}{Colors.BOLD}{title:^60}{Colors.END}")
    print(f"{Colors.CYAN}{Colors.BOLD}{'='*60}{Colors.END}")

def print_success(message: str):
    """æ‰“å°æˆåŠŸæ¶ˆæ¯"""
    print(f"{Colors.GREEN}âœ“ {message}{Colors.END}")

def print_error(message: str):
    """æ‰“å°é”™è¯¯æ¶ˆæ¯"""
    print(f"{Colors.RED}âœ— {message}{Colors.END}")

def print_warning(message: str):
    """æ‰“å°è­¦å‘Šæ¶ˆæ¯"""
    print(f"{Colors.YELLOW}âš  {message}{Colors.END}")

def print_info(message: str):
    """æ‰“å°ä¿¡æ¯æ¶ˆæ¯"""
    print(f"{Colors.BLUE}â„¹ {message}{Colors.END}")

def create_mock_messages() -> List[Dict[str, Any]]:
    """åˆ›å»ºæ¨¡æ‹ŸèŠå¤©æ¶ˆæ¯"""
    return [
        {
            "role": "user",
            "content": "ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹æœºå™¨å­¦ä¹ ä¸­çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯ã€‚"
        },
        {
            "role": "assistant", 
            "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å¤æ‚æ¨¡å¼ã€‚ä¸»è¦åŒ…æ‹¬å·ç§¯ç¥ç»ç½‘ç»œ(CNN)ã€å¾ªç¯ç¥ç»ç½‘ç»œ(RNN)ç­‰æ¶æ„ã€‚"
        },
        {
            "role": "user",
            "content": "èƒ½è¯¦ç»†ä»‹ç»ä¸€ä¸‹ç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†å—ï¼Ÿç‰¹åˆ«æ˜¯åå‘ä¼ æ’­ç®—æ³•ã€‚"
        }
    ]

def create_test_input(
    messages: List[Dict[str, Any]], 
    api_key: str = DEEPSEEK_CONFIG["api_key"],
    model: str = DEEPSEEK_CONFIG["model"],
    stream: bool = False
) -> Dict[str, Any]:
    """åˆ›å»ºæµ‹è¯•è¾“å…¥æ•°æ®"""
    return {
        "request_id": str(uuid.uuid4()),
        "original_messages": messages.copy(),
        "messages": messages.copy(),
        "current_scenario": "",  # å°†ç”±å·¥ä½œæµè¯»å–
        "api_key": api_key,
        "model": model,
        "stream": stream
    }

def validate_workflow_output(result: Dict[str, Any]) -> tuple[bool, str]:
    """éªŒè¯å·¥ä½œæµè¾“å‡ºç»“æœ"""
    try:
        # æ£€æŸ¥å¿…éœ€çš„è¾“å‡ºå­—æ®µ
        required_fields = ["memory_flashback", "final_scenario", "llm_response"]
        missing_fields = []
        
        for field in required_fields:
            if field not in result:
                missing_fields.append(field)
        
        if missing_fields:
            return False, f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}"
        
        # æ£€æŸ¥è®°å¿†é—ªå›ç»“æœ
        memory_flashback = result.get("memory_flashback", "")
        if not memory_flashback or len(memory_flashback.strip()) < 10:
            return False, "è®°å¿†é—ªå›ç»“æœä¸ºç©ºæˆ–è¿‡çŸ­"
        
        # æ£€æŸ¥æƒ…æ™¯æ›´æ–°ç»“æœ
        final_scenario = result.get("final_scenario", "")
        if not final_scenario or len(final_scenario.strip()) < 10:
            return False, "æœ€ç»ˆæƒ…æ™¯ç»“æœä¸ºç©ºæˆ–è¿‡çŸ­"
        
        # æ£€æŸ¥LLMå“åº”
        llm_response = result.get("llm_response")
        if not llm_response:
            return False, "LLMå“åº”ä¸ºç©º"
        
        # æ£€æŸ¥LLMå“åº”å†…å®¹
        if hasattr(llm_response, 'content'):
            content = llm_response.content
        elif isinstance(llm_response, dict):
            content = llm_response.get('content', '')
        else:
            content = str(llm_response)
        
        if not content or len(content.strip()) < 10:
            return False, "LLMå“åº”å†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­"
        
        return True, "æ‰€æœ‰è¾“å‡ºéªŒè¯é€šè¿‡"
        
    except Exception as e:
        return False, f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}"

def print_workflow_result(result: Dict[str, Any]):
    """æ‰“å°å·¥ä½œæµç»“æœè¯¦æƒ…"""
    print(f"\n{Colors.PURPLE}--- å·¥ä½œæµæ‰§è¡Œç»“æœ ---{Colors.END}")
    
    # æ‰“å°è®°å¿†é—ªå›ç»“æœ
    memory_flashback = result.get("memory_flashback", "")
    print(f"{Colors.YELLOW}è®°å¿†é—ªå›ç»“æœ ({len(memory_flashback)} å­—ç¬¦):{Colors.END}")
    print(f"{memory_flashback[:200]}..." if len(memory_flashback) > 200 else memory_flashback)
    
    # æ‰“å°æƒ…æ™¯æ›´æ–°ç»“æœ
    final_scenario = result.get("final_scenario", "")
    print(f"\n{Colors.YELLOW}æœ€ç»ˆæƒ…æ™¯ ({len(final_scenario)} å­—ç¬¦):{Colors.END}")
    print(f"{final_scenario[:200]}..." if len(final_scenario) > 200 else final_scenario)
    
    # æ‰“å°LLMå“åº”
    llm_response = result.get("llm_response")
    if llm_response:
        if hasattr(llm_response, 'content'):
            content = llm_response.content
        elif isinstance(llm_response, dict):
            content = llm_response.get('content', str(llm_response))
        else:
            content = str(llm_response)
        
        print(f"\n{Colors.YELLOW}LLMæœ€ç»ˆå“åº” ({len(content)} å­—ç¬¦):{Colors.END}")
        print(f"{content[:300]}..." if len(content) > 300 else content)
    
    print(f"{Colors.PURPLE}--- ç»“æœæ‰“å°å®Œæ¯• ---{Colors.END}\n")

async def test_complete_workflow() -> bool:
    """æµ‹è¯•å®Œæ•´å·¥ä½œæµæ‰§è¡Œ"""
    print_header("æµ‹è¯•1: å®Œæ•´å·¥ä½œæµæ‰§è¡Œ")
    
    try:
        # åˆ›å»ºå·¥ä½œæµå’Œæµ‹è¯•æ•°æ®
        workflow = create_scenario_workflow()
        messages = create_mock_messages()
        test_input = create_test_input(messages)
        
        print_info(f"æµ‹è¯•è¾“å…¥ - æ¶ˆæ¯æ•°é‡: {len(messages)}")
        print_info(f"ä½¿ç”¨æ¨¡å‹: {test_input['model']}")
        print_info(f"APIå¯†é’¥: {test_input['api_key'][:8]}...{test_input['api_key'][-8:]}")
        
        # æ‰§è¡Œå·¥ä½œæµ
        start_time = time.time()
        result = await workflow.ainvoke(test_input)
        duration = time.time() - start_time
        
        print_info(f"å·¥ä½œæµæ‰§è¡Œè€—æ—¶: {duration:.2f}ç§’")
        
        # éªŒè¯ç»“æœ
        is_valid, message = validate_workflow_output(result)
        if is_valid:
            print_success(f"å®Œæ•´å·¥ä½œæµæµ‹è¯•é€šè¿‡: {message}")
            print_workflow_result(result)
            return True
        else:
            print_error(f"å®Œæ•´å·¥ä½œæµæµ‹è¯•å¤±è´¥: {message}")
            return False
            
    except Exception as e:
        print_error(f"å®Œæ•´å·¥ä½œæµæµ‹è¯•å¼‚å¸¸: {str(e)}")
        import traceback
        print(f"{Colors.RED}{traceback.format_exc()}{Colors.END}")
        return False

async def test_streaming_mode() -> bool:
    """æµ‹è¯•æµå¼è¾“å‡ºæ¨¡å¼"""
    print_header("æµ‹è¯•2: æµå¼è¾“å‡ºæ¨¡å¼")
    
    try:
        # åˆ›å»ºå·¥ä½œæµå’Œæµ‹è¯•æ•°æ®
        workflow = create_scenario_workflow()
        messages = create_mock_messages()
        test_input = create_test_input(messages, stream=True)
        
        print_info("å¼€å§‹æµå¼è¾“å‡ºæµ‹è¯•...")
        
        # æ”¶é›†æµå¼è¾“å‡º
        stream_chunks = []
        start_time = time.time()
        
        async for msg, metadata in workflow.astream(
            test_input,
            stream_mode="messages"
        ):
            if hasattr(msg, 'content') and msg.content:
                stream_chunks.append(msg.content)
                print(f"{Colors.GREEN}æµå¼è¾“å‡º: {msg.content[:50]}...{Colors.END}")
            elif isinstance(msg, dict):
                content = extract_content_from_event(msg)
                if content:
                    stream_chunks.append(content)
                    print(f"{Colors.GREEN}æµå¼è¾“å‡º: {content[:50]}...{Colors.END}")
        
        duration = time.time() - start_time
        
        print_info(f"æµå¼è¾“å‡ºè€—æ—¶: {duration:.2f}ç§’")
        print_info(f"æ”¶é›†åˆ° {len(stream_chunks)} ä¸ªæµå¼å—")
        
        if len(stream_chunks) > 0:
            total_content = ''.join(stream_chunks)
            print_info(f"æ€»æµå¼å†…å®¹é•¿åº¦: {len(total_content)} å­—ç¬¦")
            print_success("æµå¼è¾“å‡ºæµ‹è¯•é€šè¿‡")
            return True
        else:
            print_error("æµå¼è¾“å‡ºæµ‹è¯•å¤±è´¥: æ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•æµå¼å—")
            return False
            
    except Exception as e:
        print_error(f"æµå¼è¾“å‡ºæµ‹è¯•å¼‚å¸¸: {str(e)}")
        import traceback
        print(f"{Colors.RED}{traceback.format_exc()}{Colors.END}")
        return False

async def test_non_streaming_mode() -> bool:
    """æµ‹è¯•éæµå¼è¾“å‡ºæ¨¡å¼"""
    print_header("æµ‹è¯•3: éæµå¼è¾“å‡ºæ¨¡å¼")
    
    try:
        # åˆ›å»ºå·¥ä½œæµå’Œæµ‹è¯•æ•°æ®
        workflow = create_scenario_workflow()
        messages = create_mock_messages()
        test_input = create_test_input(messages, stream=False)
        
        print_info("å¼€å§‹éæµå¼è¾“å‡ºæµ‹è¯•...")
        
        # æ‰§è¡Œå·¥ä½œæµ
        start_time = time.time()
        result = await workflow.ainvoke(test_input)
        duration = time.time() - start_time
        
        print_info(f"éæµå¼æ‰§è¡Œè€—æ—¶: {duration:.2f}ç§’")
        
        # éªŒè¯ç»“æœå¹¶è½¬æ¢ä¸ºOpenAIæ ¼å¼
        is_valid, message = validate_workflow_output(result)
        if is_valid:
            # æµ‹è¯•æ ¼å¼è½¬æ¢
            llm_response = result.get("llm_response")
            openai_response = convert_final_response(
                llm_response, 
                test_input["model"], 
                stream=False
            )
            
            print_info("OpenAIæ ¼å¼è½¬æ¢æˆåŠŸ")
            print_info(f"è½¬æ¢åå“åº”ID: {openai_response.get('id', 'N/A')}")
            print_info(f"è½¬æ¢åæ¨¡å‹: {openai_response.get('model', 'N/A')}")
            
            print_success(f"éæµå¼è¾“å‡ºæµ‹è¯•é€šè¿‡: {message}")
            return True
        else:
            print_error(f"éæµå¼è¾“å‡ºæµ‹è¯•å¤±è´¥: {message}")
            return False
            
    except Exception as e:
        print_error(f"éæµå¼è¾“å‡ºæµ‹è¯•å¼‚å¸¸: {str(e)}")
        import traceback
        print(f"{Colors.RED}{traceback.format_exc()}{Colors.END}")
        return False

async def test_error_handling() -> bool:
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print_header("æµ‹è¯•4: é”™è¯¯å¤„ç†")
    
    test_passed = 0
    total_tests = 2
    
    try:
        workflow = create_scenario_workflow()
        messages = create_mock_messages()
        
        # æµ‹è¯•1: æ— æ•ˆAPIå¯†é’¥
        print_info("æµ‹è¯•å­é¡¹1: æ— æ•ˆAPIå¯†é’¥å¤„ç†")
        try:
            invalid_input = create_test_input(messages, api_key="invalid_key")
            result = await workflow.ainvoke(invalid_input)
            # å¦‚æœåˆ°è¿™é‡Œæ²¡æœ‰å¼‚å¸¸ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯å“åº”
            llm_response = result.get("llm_response")
            if llm_response and hasattr(llm_response, 'content'):
                content = llm_response.content
                if "Error" in content or "error" in content:
                    print_success("æ— æ•ˆAPIå¯†é’¥é”™è¯¯å¤„ç†æ­£ç¡®")
                    test_passed += 1
                else:
                    print_warning("æ— æ•ˆAPIå¯†é’¥æœªè§¦å‘é¢„æœŸé”™è¯¯")
            else:
                print_warning("æ— æ•ˆAPIå¯†é’¥æµ‹è¯•ç»“æœä¸æ˜ç¡®")
        except Exception as e:
            print_success(f"æ— æ•ˆAPIå¯†é’¥æ­£ç¡®è§¦å‘å¼‚å¸¸: {str(e)[:100]}...")
            test_passed += 1
        
        # æµ‹è¯•2: ç©ºæ¶ˆæ¯åˆ—è¡¨
        print_info("æµ‹è¯•å­é¡¹2: ç©ºæ¶ˆæ¯åˆ—è¡¨å¤„ç†")
        try:
            empty_input = create_test_input([])
            result = await workflow.ainvoke(empty_input)
            # å·¥ä½œæµåº”è¯¥èƒ½å¤„ç†ç©ºæ¶ˆæ¯ï¼Œä½†å¯èƒ½äº§ç”Ÿé»˜è®¤å“åº”
            print_success("ç©ºæ¶ˆæ¯åˆ—è¡¨å¤„ç†æ­£å¸¸")
            test_passed += 1
        except Exception as e:
            print_success(f"ç©ºæ¶ˆæ¯åˆ—è¡¨æ­£ç¡®è§¦å‘å¼‚å¸¸: {str(e)[:100]}...")
            test_passed += 1
        
        if test_passed >= total_tests // 2:  # è‡³å°‘é€šè¿‡ä¸€åŠæµ‹è¯•
            print_success(f"é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡ ({test_passed}/{total_tests})")
            return True
        else:
            print_error(f"é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥ ({test_passed}/{total_tests})")
            return False
            
    except Exception as e:
        print_error(f"é”™è¯¯å¤„ç†æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False

async def run_all_tests() -> Dict[str, bool]:
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹"""
    print_header("DeepRolePlay å·¥ä½œæµæµ‹è¯•å¥—ä»¶")
    print_info(f"æµ‹è¯•å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print_info(f"ä»£ç†LLMé…ç½®: {settings.agent.model} @ {settings.agent.base_url}")
    print_info(f"è½¬å‘LLMé…ç½®: {DEEPSEEK_CONFIG['model']} @ {DEEPSEEK_CONFIG['base_url']}")
    
    # æµ‹è¯•ç»“æœè®°å½•
    test_results = {}
    
    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    test_results["complete_workflow"] = await test_complete_workflow()
    test_results["streaming_mode"] = await test_streaming_mode()
    test_results["non_streaming_mode"] = await test_non_streaming_mode()
    test_results["error_handling"] = await test_error_handling()
    
    return test_results

def print_final_report(test_results: Dict[str, bool]):
    """æ‰“å°æœ€ç»ˆæµ‹è¯•æŠ¥å‘Š"""
    print_header("æµ‹è¯•ç»“æœæŠ¥å‘Š")
    
    passed_tests = sum(test_results.values())
    total_tests = len(test_results)
    
    print(f"{Colors.BOLD}æµ‹è¯•æ¦‚è§ˆ:{Colors.END}")
    print(f"  æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"  é€šè¿‡æµ‹è¯•: {Colors.GREEN}{passed_tests}{Colors.END}")
    print(f"  å¤±è´¥æµ‹è¯•: {Colors.RED}{total_tests - passed_tests}{Colors.END}")
    print(f"  é€šè¿‡ç‡: {Colors.CYAN}{(passed_tests/total_tests)*100:.1f}%{Colors.END}")
    
    print(f"\n{Colors.BOLD}è¯¦ç»†ç»“æœ:{Colors.END}")
    for test_name, result in test_results.items():
        status = f"{Colors.GREEN}âœ“ PASS{Colors.END}" if result else f"{Colors.RED}âœ— FAIL{Colors.END}"
        print(f"  {test_name.replace('_', ' ').title()}: {status}")
    
    if passed_tests == total_tests:
        print(f"\n{Colors.GREEN}{Colors.BOLD}ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å·¥ä½œæµé‡æ„æˆåŠŸï¼{Colors.END}")
    elif passed_tests >= total_tests * 0.7:  # 70%é€šè¿‡ç‡
        print(f"\n{Colors.YELLOW}{Colors.BOLD}âš  å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œå»ºè®®æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•{Colors.END}")
    else:
        print(f"\n{Colors.RED}{Colors.BOLD}âŒ å¤šä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å·¥ä½œæµå®ç°{Colors.END}")

if __name__ == "__main__":
    print(f"{Colors.CYAN}å¯åŠ¨ DeepRolePlay å·¥ä½œæµæµ‹è¯•...{Colors.END}\n")
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        results = asyncio.run(run_all_tests())
        
        # æ‰“å°æœ€ç»ˆæŠ¥å‘Š
        print_final_report(results)
        
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­{Colors.END}")
    except Exception as e:
        print(f"\n{Colors.RED}æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}{Colors.END}")
        import traceback
        print(f"{Colors.RED}{traceback.format_exc()}{Colors.END}")